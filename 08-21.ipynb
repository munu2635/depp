{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  4.  6.  8. 10.]\n"
     ]
    }
   ],
   "source": [
    "# tensorflow - placeholder 외부에서 학습 데이터가 주입되는 저장공간\n",
    "# placeholder에 학습 데이트를 주입하는 것을 feeding 이라 함\n",
    "import tensorflow as tf\n",
    "\n",
    "# 정의 부분 \n",
    "input_data = [1, 2, 3, 4, 5]\n",
    "x = tf.placeholder(dtype = tf.float32)\n",
    "y = x*2\n",
    "\n",
    "# 실행부분\n",
    "sess = tf.Session()\n",
    "result = sess.run(y,feed_dict={x:input_data})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  4.  6.  8. 10.]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable([2],dtype=tf.float32)\n",
    "y = W*x\n",
    "\n",
    "# 텐서플로에서 variable은 그래프를 실행하기전에 반드시 초기화를 해주어야한다.\n",
    "init = tf.global_variables_initializer() \n",
    "sess.run(init)\n",
    "result = sess.run(y, feed_dict={x:input_data})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 24.344395 [2.6440656] [1.6383724]\n",
      "1 11.071514 [0.858781] [0.98866516]\n",
      "2 5.103898 [2.0762768] [1.3615416]\n",
      "3 2.416702 [1.2810907] [1.0510949]\n",
      "4 1.2028201 [1.8339071] [1.2003305]\n",
      "5 0.6508632 [1.4828811] [1.0433108]\n",
      "6 0.39650857 [1.7369041] [1.0932081]\n",
      "7 0.27615714 [1.5849438] [1.0061144]\n",
      "8 0.21633348 [1.7044709] [1.0124196]\n",
      "9 0.18402703 [1.6415547] [0.9577002]\n",
      "10 0.16439669 [1.7003726] [0.94538283]\n",
      "11 0.15076002 [1.6771224] [0.90612]\n",
      "12 0.14009884 [1.7083789] [0.88633484]\n",
      "13 0.13104118 [1.7026432] [0.8548784]\n",
      "14 0.122955576 [1.7212392] [0.83258116]\n",
      "15 0.11554335 [1.7230898] [0.8054453]\n",
      "16 0.10865651 [1.7357324] [0.78281134]\n",
      "17 0.10221548 [1.7407281] [0.75838286]\n",
      "18 0.09617211 [1.7504445] [0.73634225]\n",
      "19 0.0904932 [1.7566066] [0.7138515]\n",
      "20 0.08515285 [1.764771] [0.69277793]\n",
      "21 0.080129065 [1.7712255] [0.67183685]\n",
      "22 0.07540235 [1.7784688] [0.6518568]\n",
      "23 0.0709547 [1.7848371] [0.632251]\n",
      "24 0.06676954 [1.791456] [0.6133823]\n",
      "25 0.062831365 [1.7975808] [0.59497786]\n",
      "26 0.05912543 [1.8037206] [0.5771918]\n",
      "27 0.0556381 [1.8095437] [0.55989313]\n",
      "28 0.05235646 [1.8152815] [0.5431426]\n",
      "29 0.049268376 [1.8207879] [0.5268733]\n",
      "30 0.046362456 [1.8261695] [0.5111047]\n",
      "31 0.043627888 [1.831363] [0.49579903]\n",
      "32 0.041054662 [1.836419] [0.48095772]\n",
      "33 0.03863319 [1.8413117] [0.4665567]\n",
      "34 0.036354546 [1.8460659] [0.4525895]\n",
      "35 0.034210276 [1.8506724] [0.4390387]\n",
      "36 0.03219247 [1.8551445] [0.42589477]\n",
      "37 0.030293722 [1.8594804] [0.41314358]\n",
      "38 0.028506957 [1.863688] [0.40077466]\n",
      "39 0.02682557 [1.8677688] [0.38877577]\n",
      "40 0.02524335 [1.8717277] [0.37713623]\n",
      "41 0.02375445 [1.875568] [0.36584514]\n",
      "42 0.022353351 [1.8792934] [0.3548921]\n",
      "43 0.021034922 [1.8829072] [0.34426695]\n",
      "44 0.01979425 [1.886413] [0.33396]\n",
      "45 0.018626738 [1.8898135] [0.32396153]\n",
      "46 0.017528117 [1.8931124] [0.31426242]\n",
      "47 0.016494278 [1.8963126] [0.3048537]\n",
      "48 0.015521415 [1.8994168] [0.29572666]\n",
      "49 0.014605927 [1.9024283] [0.28687292]\n",
      "50 0.0137444725 [1.9053494] [0.2782842]\n",
      "51 0.012933796 [1.9081832] [0.26995265]\n",
      "52 0.012170915 [1.9109321] [0.2618705]\n",
      "53 0.011453055 [1.9135988] [0.2540304]\n",
      "54 0.01077755 [1.9161855] [0.24642497]\n",
      "55 0.01014186 [1.9186947] [0.2390472]\n",
      "56 0.009543687 [1.9211291] [0.2318904]\n",
      "57 0.008980781 [1.9234903] [0.2249478]\n",
      "58 0.008451068 [1.9257809] [0.2182131]\n",
      "59 0.007952634 [1.928003] [0.21168001]\n",
      "60 0.007483571 [1.9301585] [0.20534252]\n",
      "61 0.0070421677 [1.9322495] [0.1991948]\n",
      "62 0.006626814 [1.9342778] [0.19323105]\n",
      "63 0.0062359497 [1.9362456] [0.18744592]\n",
      "64 0.0058681355 [1.9381542] [0.18183394]\n",
      "65 0.0055220295 [1.940006] [0.17639007]\n",
      "66 0.005196333 [1.9418019] [0.17110904]\n",
      "67 0.0048898347 [1.9435445] [0.16598627]\n",
      "68 0.0046014306 [1.9452347] [0.16101678]\n",
      "69 0.004330024 [1.9468743] [0.15619609]\n",
      "70 0.004074625 [1.9484649] [0.15151975]\n",
      "71 0.003834308 [1.9500077] [0.14698336]\n",
      "72 0.0036081546 [1.9515046] [0.14258286]\n",
      "73 0.0033953274 [1.9529563] [0.13831401]\n",
      "74 0.0031950856 [1.9543649] [0.13417307]\n",
      "75 0.0030066273 [1.955731] [0.13015601]\n",
      "76 0.0028292781 [1.9570565] [0.1262593]\n",
      "77 0.0026624117 [1.9583421] [0.12247917]\n",
      "78 0.002505379 [1.9595895] [0.11881233]\n",
      "79 0.0023576044 [1.960799] [0.11525509]\n",
      "80 0.0022185522 [1.9619731] [0.11180462]\n",
      "81 0.0020877004 [1.9631112] [0.10845718]\n",
      "82 0.0019645577 [1.9642159] [0.10521017]\n",
      "83 0.0018486835 [1.965287] [0.10206018]\n",
      "84 0.0017396447 [1.9663264] [0.09900466]\n",
      "85 0.0016370364 [1.9673345] [0.09604054]\n",
      "86 0.0015404837 [1.9683124] [0.09316517]\n",
      "87 0.0014496248 [1.9692612] [0.09037591]\n",
      "88 0.0013641238 [1.9701815] [0.08767014]\n",
      "89 0.0012836634 [1.9710741] [0.08504535]\n",
      "90 0.0012079524 [1.9719403] [0.08249924]\n",
      "91 0.0011367069 [1.9727803] [0.08002926]\n",
      "92 0.0010696595 [1.9735951] [0.0776332]\n",
      "93 0.0010065676 [1.9743857] [0.07530896]\n",
      "94 0.00094720273 [1.9751527] [0.07305432]\n",
      "95 0.00089133286 [1.9758965] [0.07086711]\n",
      "96 0.00083876523 [1.9766182] [0.06874543]\n",
      "97 0.0007892876 [1.9773182] [0.06668725]\n",
      "98 0.00074273796 [1.9779973] [0.06469073]\n",
      "99 0.0006989303 [1.978656] [0.06275395]\n",
      "\n",
      "=== Test ===\n",
      "X: 5, Y: [9.956034]\n",
      "X: 2.5, Y: [5.009394]\n"
     ]
    }
   ],
   "source": [
    "## Linear Regression 구현 - 선형 회귀 \n",
    "# X 와 Y 의 상관관계를 분석하는 기초적인 선형 회귀 모델을 만들고 실행해봅니다.\n",
    "import tensorflow as tf\n",
    "\n",
    "x_data = [1, 2, 3, 4]\n",
    "y_data = [2, 4, 6, 8]\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "\n",
    "# name: 나중에 텐서보드등으로 값의 변화를 추적하거나 살펴보기 쉽게 하기 위해 이름을 붙여줍니다.\n",
    "X = tf.placeholder(tf.float32, name=\"X\")\n",
    "Y = tf.placeholder(tf.float32, name=\"Y\")\n",
    "\n",
    "# X 와 Y 의 상관 관계를 분석하기 위한 가설 수식을 작성합니다.\n",
    "# y = W * x + b\n",
    "# W 와 X 가 행렬이 아니므로 tf.matmul 이 아니라 기본 곱셈 기호를 사용했습니다.\n",
    "hypothesis = W * X + b\n",
    "\n",
    "# 손실 함수를 작성합니다.\n",
    "# mean(h - Y)^2 : 예측값과 실제값의 거리를 비용(손실) 함수로 정합니다.\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "# 텐서플로우에 기본적으로 포함되어 있는 함수를 이용해 경사 하강법 최적화를 수행합니다.\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "# 비용을 최소화 하는 것이 최종 목표\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "# 세션을 생성하고 초기화합니다.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # 최적화를 100번 수행합니다.\n",
    "    for step in range(100):\n",
    "        # sess.run 을 통해 train_op 와 cost 그래프를 계산합니다.\n",
    "        # 이 때, 가설 수식에 넣어야 할 실제값을 feed_dict 을 통해 전달합니다.\n",
    "        _, cost_val = sess.run([train_op, cost], feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "        print(step, cost_val, sess.run(W), sess.run(b))\n",
    "\n",
    "    # 최적화가 완료된 모델에 테스트 값을 넣고 결과가 잘 나오는지 확인해봅니다.\n",
    "    print(\"\\n=== Test ===\")\n",
    "    print(\"X: 5, Y:\", sess.run(hypothesis, feed_dict={X: 5}))\n",
    "    print(\"X: 2.5, Y:\", sess.run(hypothesis, feed_dict={X: 2.5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
